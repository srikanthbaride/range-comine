{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de68bfa4",
   "metadata": {},
   "source": [
    "# Timing vs Dataset Size (Range–CoMine vs Naïve vs RangeInc)\n",
    "This notebook measures average **runtime (ms)** and **peak memory (KB)** as we scale the number of features and instances per feature.\n",
    "\n",
    "Use this to sanity-check complexity and compare algorithms on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a778889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from range_comine.synthetic import generate_synthetic\n",
    "from range_comine.mining import range_comine\n",
    "from range_comine.baselines import naive_range, range_inc_mining\n",
    "import time, tracemalloc, statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ALGOS = {\n",
    "    \"range\": (\"Range–CoMine\", range_comine),\n",
    "    \"naive\": (\"Naïve\", naive_range),\n",
    "    \"range_inc\": (\"RangeInc-Mining\", range_inc_mining),\n",
    "}\n",
    "\n",
    "def run_profile(fn, objs, d1, d2, min_prev):\n",
    "    tracemalloc.start()\n",
    "    t0 = time.perf_counter()\n",
    "    col = fn(objs, d1=d1, d2=d2, min_prev=min_prev)\n",
    "    ms = (time.perf_counter() - t0) * 1000.0\n",
    "    _, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    return ms, peak/1024.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sizes = [(3,5), (4,6), (5,6), (6,6)]  # (n_features, instances_per_feature)\n",
    "d1, d2, min_prev = 8.0, 30.0, 0.5\n",
    "seed = 13\n",
    "reps = 3  # average\n",
    "results = {a: [] for a in ALGOS.keys()}\n",
    "\n",
    "for (nf, ni) in sizes:\n",
    "    objs = generate_synthetic(n_features=nf, instances_per_feat=ni, seed=seed)\n",
    "    for key, (name, fn) in ALGOS.items():\n",
    "        tms, pks = [], []\n",
    "        for _ in range(reps):\n",
    "            ms, pk = run_profile(fn, objs, d1, d2, min_prev)\n",
    "            tms.append(ms); pks.append(pk)\n",
    "        results[key].append((nf*ni, sum(tms)/len(tms), sum(pks)/len(pks)))\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85592d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot runtime\n",
    "plt.figure()\n",
    "for key, series in results.items():\n",
    "    xs = [n for (n,ms,pk) in series]\n",
    "    ys = [ms for (n,ms,pk) in series]\n",
    "    plt.plot(xs, ys, marker=\"o\", label=ALGOS[key][0])\n",
    "plt.xlabel(\"Total #objects (n_features × instances_per_feature)\")\n",
    "plt.ylabel(\"Avg runtime (ms)\")\n",
    "plt.title(\"Runtime vs dataset size\")\n",
    "plt.legend(); plt.grid(True, linestyle=\"--\", alpha=0.6); plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c572981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot memory\n",
    "plt.figure()\n",
    "for key, series in results.items():\n",
    "    xs = [n for (n,ms,pk) in series]\n",
    "    ys = [pk for (n,ms,pk) in series]\n",
    "    plt.plot(xs, ys, marker=\"o\", label=ALGOS[key][0])\n",
    "plt.xlabel(\"Total #objects (n_features × instances_per_feature)\")\n",
    "plt.ylabel(\"Avg peak memory (KB)\")\n",
    "plt.title(\"Peak memory vs dataset size\")\n",
    "plt.legend(); plt.grid(True, linestyle=\"--\", alpha=0.6); plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
